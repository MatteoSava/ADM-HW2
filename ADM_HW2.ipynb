{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steam_analysis import count_languages,\\\n",
    "                           sort_count,\\\n",
    "                           languages_pie,\\\n",
    "                           print_top_languages,\\\n",
    "                           filter_by_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Languages\n",
    "First, we want to check in what languages most of the reviews are written in. We can do this by grouping the dataset by its `language` column, then by counting how many unique elements (languages) there are by using the `size()` method, and finally by sorting it and slicing the top 3.\n",
    "\n",
    "We can manage to load the whole dataset by only selecting the columns we will need for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/steam_reviews.csv\", \n",
    "                 usecols = ['review_id', 'language', 'votes_funny', 'votes_helpful'], \n",
    "                 header = 'infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the most common languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_pie(df['language'])\n",
    "\n",
    "top_languages = sort_count(count_languages(df))\n",
    "\n",
    "print_top_languages(top_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's filter the dataset so it only includes reviews in these languages\n",
    "\n",
    "How did other users consider these reviews: Funny or Helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_by_language(df, [language for language, _ in top_languages])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steam_analysis import compute_prob, format_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only import the columns we need, so we can keep memory usage to a minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/steam_reviews.csv\", \n",
    "                 usecols = ['review_id', 'votes_funny', 'weighted_vote_score'], \n",
    "                 header = 'infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Vote Score\n",
    "\n",
    "We want to know what's the probability of a review having a *WVS* of at least 0.5.\n",
    "\n",
    "In order to do so, let's take a first look into how these scores are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weighted_vote_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution has a mean of about 0.16, and about 3/4 of the votes are below 0.5. \n",
    "\n",
    "This tells us that we should expect a low figure for $\\mathcal{P}(score \\geq 0.5)$\n",
    "\n",
    "In order to get a better grasp of this data, we should plot an histogram of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 20\n",
    "\n",
    "plt.hist(df['weighted_vote_score'], bins = n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of reviews have a Weighted Vote Score of exactly 0, so instead on working with the entire dataset, let's only focus on those reviews which have a non-zero score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs = df[df['weighted_vote_score'] > 0]\n",
    "\n",
    "print(wvs['weighted_vote_score'].describe())\n",
    "\n",
    "print(wvs['weighted_vote_score'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 1/3 of the reviews have a non-zero score. The mean now is very close to 0.5 and the distribution is (probability-wise) symmetric about 0.52; as we can visualize from the updated histogram the scores seem normally distributed, although the right tail is heavier than the left one: reviews tend to have a score higher than 0.5 more likely than lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(wvs['weighted_vote_score'], bins = n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the probability of $\\mathcal{P}(score \\geq 0.5)$ we can sum up the number of elements contained in each bin in the interval $[0.5, 1.0]$ and then divide the value we get by the total number of binned elements.\n",
    "\n",
    "This is easily done by operating directly on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_wvs = compute_prob(wvs, 'weighted_vote_score', 0.5)\n",
    "\n",
    "format_prob(prob_wvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 2/3 of the reviews have a Weighted Vote Score of at least 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, by considering the original dataset we would have gotten only about 1/5 of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_wvs_orig = compute_prob(df, 'weighted_vote_score', 0.5)\n",
    "\n",
    "format_prob(prob_wvs_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a deeper look into these reviews\n",
    "\n",
    "We want to study the correlation between a review having a *WVS* bigger than or equal to 0.5 and it being rated as 'Funny'.\n",
    "\n",
    "First, let's compute the probability of a review having $WVS \\geq 0.5$ and at least one 'Funny' vote:\n",
    "\n",
    "$\\mathcal{P}(WVS \\geq 0.5\\: \\text{and}\\: funny \\geq 1)$\n",
    "\n",
    "Just like before, we can filter the dataset and then divide the number of reviews in the filtered dataset by the total number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_funny = df[(df['weighted_vote_score'] >= 0.5) & df['votes_funny'] > 0]['review_id']\n",
    "\n",
    "prob_wvs_funny = compute_prob(wvs_funny, 'weighted_vote_score', 0.5)\n",
    "\n",
    "format_prob(prob_wvs_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are these two events independent?\n",
    "\n",
    "If the probability of a review having $WVS \\geq 0.5$ and the probability of it having been rated as 'Funny' by at least one user are independent, then we expect\n",
    "\n",
    "$\\mathcal{P}(WVS \\geq 0.5\\: \\text{and}\\: funny \\geq 1) = \\mathcal{P}(WVS \\geq 0.5)\\cdot\\mathcal{P}(funny \\geq 1)$\n",
    "\n",
    "In order to check if this equality holds, let's compute $\\mathcal{P}(funny \\geq 1)$.\n",
    "\n",
    "We will filter these reviews out of the dataset which contains only reviews with non-zero *WVS*'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_funny = compute_prob(wvs, 'votes_funny', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the difference between the probability of the intersection of these two events, and the product of the probabilities of the two single events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(prob_wvs_funny - prob_wvs * prob_funny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is too large to be negligible: the two events can't be considered independent."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
